#!CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.78 --force-reinstall --upgrade --no-cache-dir --verbose

langchain==0.0.271
llama_cpp_python==0.1.77
matplotlib==3.7.1
pandas==1.5.3
scipy==1.8.1
seaborn==0.12.2
streamlit==1.25.0
sentence_transformers
faiss-gpu
#faiss_cpu
huggingface_hub

# torch
# accelerate
# bitsandbytes
# transformers
# streamlit-chat
# ctransformers